export const de = {
  nav: {
    dashboard: 'Dashboard',
    assessment: 'Assessment',
    results: 'Ergebnisse',
  },
  dashboard: {
    title: 'Reifegradmodell fÃ¼r Hochrisiko-KI-Governance',
    subtitle: 'Selbstbewertung der organisationalen KI-Governance-Reife gemÃ¤ÃŸ Art. 9â€“15 EU AI Act (VO 2024/1689) fÃ¼r Hochrisiko-KI-Systeme.',
    criteriaCount: 'Kriterien',
    clickForDetails: 'Klicken fÃ¼r Details â†’',
    howItWorksTitle: 'So funktioniert das Assessment',
    step1Label: '31 Kriterien bewerten',
    step1Desc: 'â€” sechs Dimensionen (D1â€“D6)',
    step2Label: 'Automatisches Scoring',
    step2Desc: 'â€” Dimensions- & Gesamtscores',
    step3Label: 'Gap-Analyse',
    step3Desc: 'â€” priorisierte Handlungsempfehlungen',
    startAssessment: 'Assessment starten',
    valueMaturity: 'Maturity-Score nach CMMI',
    valueGapAnalysis: 'Gap-Analyse mit PrioritÃ¤ten',
    valueActionPlan: 'Aktionsplan mit Quick Wins',
    valueRegulatory: 'Regulatorische Risikobewertung',
    timeEstimate: 'ca. 15â€“20 Min. (Einzelbewertung)',
    progressTitle: 'Assessment in Bearbeitung',
    progressDesc: '{rated} von {total} Kriterien bewertet',
    progressLabel: 'Assessment-Fortschritt',
    continueAssessment: 'Fortfahren',
    resultsAvailable: 'Ergebnisse verfÃ¼gbar',
    resultsAvailableDesc: 'Ihr letztes Assessment-Ergebnis ist gespeichert.',
    viewResults: 'Ergebnisse ansehen',
    resetAssessment: 'ZurÃ¼cksetzen',
    historyTitle: 'Bisherige Bewertungen',
    loadError: 'Dimensionen konnten nicht geladen werden. Ist das Backend erreichbar?',
    retry: 'Erneut versuchen',
    valuePropositions: 'Leistungsmerkmale des Assessments',
    methodologyTitle: 'Wissenschaftliche Grundlage',
    methodologyDesc: 'Dieses Assessment basiert auf einem Reifegradmodell, das im Rahmen einer Masterarbeit im Studiengang M.Sc. Technologie & Management an der Provadis School of International Management & Technology in Zusammenarbeit mit Accenture entwickelt wurde. Es verbindet Anforderungen des EU AI Acts (VO 2024/1689, Art. 9â€“15) mit dem CMMI-Reifegradansatz (5 Stufen) und evaluiert sechs Governance-Dimensionen anhand von 31 Kriterien.',
    methodologyScoring: 'Scoring: DimScore = arithmetisches Mittel der bewerteten Kriterien je Dimension Â· GesamtScore = gewichtete Summe aller DimScores Â· Gap-Analyse mit risikokategorieabhÃ¤ngigen Schwellenwerten',
    methodologySources: 'Bezugsrahmen: EU AI Act (VO 2024/1689) Â· CMMI Institute (2018) Â· ISO/IEC 42001:2023 Â· NIST AI RMF 1.0',
  },
  assessment: {
    summary: 'Zusammenfassung',
    scoping: 'Scoping',
    overview: 'Ãœbersicht',
    stepOf: 'Schritt {current} von {total}',
    scopingTitle: 'Schritt 1: Scoping',
    scopingDesc: 'Definieren Sie das zu bewertende KI-System und den organisationalen Kontext.',
    extendedScopingDesc: 'Erweiterte Angaben â€” Optionale Details fÃ¼r prÃ¤zisere Ergebnisse.',
    systemNameLabel: 'Name des KI-Systems *',
    systemNamePlaceholder: 'z.B. Kreditscoring-System',
    riskCategoryLabel: 'Risikokategorie',
    riskCategoryHighRisk: 'Hochrisiko (Art. 6, Anhang III)',
    riskCategoryLimited: 'Begrenztes Risiko',
    riskCategoryMinimal: 'Minimales Risiko',
    industryLabel: 'Branche',
    industryPlaceholder: 'z.B. Finanzdienstleistungen',
    orgSizeLabel: 'OrganisationsgrÃ¶ÃŸe',
    orgSizeSmall: 'Klein (<50 MA)',
    orgSizeMedium: 'Mittel (50-250 MA)',
    orgSizeLarge: 'GroÃŸ (>250 MA)',
    deploymentLabel: 'Deployment-Status',
    deploymentProduction: 'Produktiv',
    deploymentPreDeployment: 'Pre-Deployment',
    startAssessment: 'Assessment starten â†’',
    riskExplanation: {
      'high-risk': 'ðŸŸ¥ Hochrisiko-KI (Anhang III): z. B. Kreditscoring, Personalauswahl, biometrische Identifikation, medizinische Diagnose. Erfordert KonformitÃ¤tsbewertung und vollstÃ¤ndige Einhaltung der Art. 9â€“15.',
      'limited-risk': 'ðŸŸ¨ Begrenztes Risiko (Art. 50): z. B. Chatbots, Emotionserkennung, Deepfake-Generierung. Transparenzpflichten, aber keine vollstÃ¤ndige KonformitÃ¤tsbewertung erforderlich.',
      'minimal-risk': 'ðŸŸ© Minimales Risiko: z. B. Spamfilter, Empfehlungssysteme, Suchmaschinen. Freiwillige Verhaltenskodizes, keine spezifischen Pflichten unter dem EU AI Act.',
    },
    mandatoryBadge: 'Pflicht fÃ¼r {risk}',
    naReasonPlaceholder: 'BegrÃ¼ndung fÃ¼r N/A (optional)...',
    naReasonHint: 'Markieren Sie N/A nur, wenn dieses Kriterium auf Ihr System nicht anwendbar ist.',
    levelExplanationTitle: 'Was bedeuten die Stufen?',
    regulatoryContext: 'Regulatorischer Kontext',
    weightingTitle: 'Dimensionsgewichtung anpassen (optional)',
    weightingDesc: 'Passen Sie die relative Wichtigkeit der Dimensionen an Ihren Kontext an. Standard: 1.0 (gleiche Gewichtung). Hochrisiko-Systeme sollten D1 und D6 hÃ¶her gewichten.',
    back: 'â† ZurÃ¼ck',
    next: 'Weiter: {name} â†’',
    toSummary: 'Zur Zusammenfassung â†’',
    summaryTitle: 'Assessment-Zusammenfassung',
    summaryDesc: 'ÃœberprÃ¼fen Sie Ihre Bewertungen bevor Sie das Assessment abschlieÃŸen.',
    systemLabel: 'System:',
    industryLabelSummary: 'Branche:',
    riskCategoryLabelSummary: 'Risikokategorie:',
    sizeLabel: 'GrÃ¶ÃŸe:',
    clickToEdit: 'klicken zum Bearbeiten',
    backToD6: 'â† ZurÃ¼ck zu D6',
    submitting: 'Auswertung...',
    submitAssessment: 'Assessment abschlieÃŸen âœ“',
    errorSubmit: 'Fehler bei der Bewertung. Ist der Backend-Server gestartet?',
  },
  results: {
    noResultsTitle: 'Keine Ergebnisse vorhanden',
    noResultsDesc: 'FÃ¼hren Sie zuerst ein Assessment durch, um Ergebnisse zu sehen.',
    startAssessment: 'Assessment starten',
  },
  bento: {
    title: 'Assessment-Ergebnisse',
    overallMaturity: 'Gesamt-Reifegrad',
    outOf: 'von 5.0 maximal',
    governanceProfile: 'Governance-Profil',
    gapAnalysis: 'Gap-Analyse',
    priorityActions: 'PrioritÃ¤re Handlungsfelder',
    dimensionScores: 'Dimensionsscores',
    dimensionHeader: 'Dimension',
    scoreHeader: 'Score',
    levelHeader: 'Stufe',
    statusHeader: 'Status',
    maturityDetail: 'Reifegrad-Detail',
    levelLabel: 'Stufe {n}: {name}',
    cmmiNote: 'CMMI-basiert (5 Stufen)',
    actions: 'Aktionen',
    newAssessment: 'Neues Assessment',
    printResults: 'Ergebnisse drucken',
    exportJSON: 'JSON exportieren',
    shareLink: 'Ergebnis-Link erstellen',
    linkCopied: 'Link kopiert!',
    pdfDownload: 'PDF-Bericht herunterladen',
    pdfGenerating: 'PDF wird erstelltâ€¦',
    dimensionsRated: '{n} Dimensionen bewertet',
    // B2: Card filter
    filterCards: 'Karten ein-/ausblenden',
    hidden: 'ausgeblendet',
    selectCards: 'Angezeigte Karten auswÃ¤hlen',
    resetFilter: 'Alle anzeigen',
    cardExecutiveSummary: 'Zusammenfassung',
    cardOverallScore: 'Gesamtscore',
    cardRadarChart: 'Radar-Diagramm',
    cardArticleCompliance: 'ArtikelkonformitÃ¤t',
    cardGapAnalysis: 'Gap-Analyse',
    cardDimensionScores: 'Dimensionsscores',
    cardComplianceHeatmap: 'Compliance-Heatmap',
    cardRoadmapTimeline: 'Roadmap',
    cardArticleMapping: 'Artikelzuordnung',
    cardComplianceTimeline: 'Compliance-Timeline',
    cardGlossary: 'Glossar',
    cardRACIMatrix: 'RACI-Matrix',
    cardMaturityDetail: 'Reifegrad-Detail',
    cardMaturityDist: 'Reifegradverteilung',
    cardActions: 'Aktionen',
  },
  gap: {
    noGaps: 'Keine kritischen Governance-LÃ¼cken identifiziert (alle Dimensionen â‰¥ 3,0).',
    showActionPlan: 'MaÃŸnahmenplan anzeigen',
    severityCritical: 'Kritisch',
    severitySignificant: 'Signifikant',
    severityModerate: 'Moderat',
    regulatoryRisk: 'Regulatorisches Risiko',
    dependencyWarning: 'AbhÃ¤ngigkeit',
    quickWinsLabel: 'Quick Wins â€” sofort umsetzbar',
    dep_D5_D1: 'D5 (Menschliche Aufsicht) baut auf D1 (Risikomanagement) auf. Ohne Risikokontext kann kein sinnvolles Aufsichtsdesign erfolgen. Empfehlung: D1 zuerst auf Level 3 bringen.',
    dep_D6_D1: 'D6 (Technische Robustheit) setzt D1 (Risikomanagement) voraus. Robustheitsanforderungen leiten sich aus der Risikobewertung ab. Empfehlung: D1 zuerst adressieren.',
    dep_D4_D3: 'D4 (Transparenz) basiert auf D3 (Dokumentation). Ohne vollstÃ¤ndige technische Dokumentation kann keine angemessene Transparenz gewÃ¤hrleistet werden.',
  },
  regulatory: {
    D1: 'Potenzielle Verletzung von Art. 9 EU AI Act (VO 2024/1689). FÃ¼r Hochrisiko-KI-Systeme ist ein dokumentiertes, Ã¼ber den gesamten Lebenszyklus aufrechterhaltenes Risikomanagementsystem verpflichtend. Sanktionsrahmen: bis 3% des weltweiten Jahresumsatzes (Art. 99 Abs. 3).',
    D2: 'Potenzielle Verletzung von Art. 10 EU AI Act. Trainings-, Validierungs- und Testdaten mÃ¼ssen definierten QualitÃ¤tskriterien entsprechen, einschlieÃŸlich Governance, ReprÃ¤sentativitÃ¤t und Bias-PrÃ¼fung. Sanktionsrahmen: bis 3% des Jahresumsatzes (Art. 99 Abs. 3).',
    D3: 'Potenzielle Verletzung von Art. 11â€“12 EU AI Act. Technische Dokumentation und automatische Protokollierung (Logging) sind vor Inverkehrbringen verpflichtend und mÃ¼ssen Ã¼ber den gesamten Lebenszyklus aufrechterhalten werden. Sanktionsrahmen: bis 3% des Jahresumsatzes.',
    D4: 'Potenzielle Verletzung von Art. 13 EU AI Act. Hochrisiko-KI-Systeme mÃ¼ssen so konzipiert sein, dass ihr Betrieb hinreichend transparent und fÃ¼r Nutzer verstÃ¤ndlich ist. Fehlende Transparenz kann zu BuÃŸgeldern bis 3% des Jahresumsatzes fÃ¼hren.',
    D5: 'Potenzielle Verletzung von Art. 14 EU AI Act. Wirksame menschliche Aufsicht muss gewÃ¤hrleistet sein, einschlieÃŸlich qualifizierter Aufsichtspersonen und InterventionsmÃ¶glichkeiten. Sanktionsrahmen: bis 3% des weltweiten Jahresumsatzes.',
    D6: 'Potenzielle Verletzung von Art. 15 EU AI Act. Hochrisiko-KI-Systeme mÃ¼ssen ein angemessenes MaÃŸ an Genauigkeit, Robustheit und Cybersicherheit aufweisen. Sanktionsrahmen: bis 3% des weltweiten Jahresumsatzes (Art. 99 Abs. 3).',
  },
  modal: {
    close: 'SchlieÃŸen',
    assessmentCriteria: 'Bewertungskriterien',
    assessThisDimension: 'Diese Dimension bewerten â†’',
    articleDescriptions: {
      'Art. 9': 'Risikomanagement â€” Art. 9 AI Act: Hochrisiko-KI-Systeme erfordern ein kontinuierliches Risikomanagementsystem Ã¼ber den gesamten Lebenszyklus.',
      'Art. 10': 'DatenqualitÃ¤t â€” Art. 10 AI Act: Trainings-, Validierungs- und TestdatensÃ¤tze mÃ¼ssen relevanten QualitÃ¤tskriterien entsprechen.',
      'Art. 11': 'Technische Dokumentation â€” Art. 11 AI Act: Umfassende technische Dokumentation muss vor Inverkehrbringen erstellt werden.',
      'Art. 12': 'Aufzeichnungspflichten â€” Art. 12 AI Act: Automatische Protokollierung (Logging) muss Ã¼ber den gesamten Lebenszyklus gewÃ¤hrleistet sein.',
      'Art. 13': 'Transparenz â€” Art. 13 AI Act: Hochrisiko-KI-Systeme mÃ¼ssen so konzipiert sein, dass ihr Betrieb hinreichend transparent ist.',
      'Art. 14': 'Menschliche Aufsicht â€” Art. 14 AI Act: Hochrisiko-KI-Systeme mÃ¼ssen wirksame menschliche Aufsicht ermÃ¶glichen.',
      'Art. 15': 'Genauigkeit & Robustheit â€” Art. 15 AI Act: Hochrisiko-KI-Systeme mÃ¼ssen ein angemessenes MaÃŸ an Genauigkeit, Robustheit und Cybersicherheit aufweisen.',
      'Art. 11â€“12': 'Dokumentation & Logging â€” Art. 11â€“12 AI Act: Technische Dokumentation und automatische Aufzeichnungspflichten fÃ¼r Hochrisiko-KI-Systeme.',
      'Art. 14â€“15': 'Aufsicht & Robustheit â€” Art. 14â€“15 AI Act: Menschliche Aufsicht, Genauigkeit, Robustheit und Cybersicherheit fÃ¼r Hochrisiko-KI-Systeme.',
    },
  },
  chat: {
    title: 'KI-Governance-Assistent',
    ragLabel: 'RAG-gestÃ¼tzt',
    allDimensions: 'Alle Dimensionen',
    placeholder: 'Frage stellen...',
    openAssistant: 'KI-Governance-Assistent Ã¶ffnen',
    emptyState: 'Stellen Sie Fragen zum Assessment, zu Dimensionen oder zum EU AI Act.',
    errorMessage: 'Fehler bei der Verbindung zum KI-Assistenten. Ist der API-Key in der .env konfiguriert?',
    starterPrompts: [
      'Was bedeutet diese Dimension konkret?',
      'Welche Best Practices gibt es?',
      'Wie erreiche ich einen hÃ¶heren Reifegrad?',
    ],
    resultsPrompts: [
      'Analysiere meine Ergebnisse und gib mir eine EinschÃ¤tzung.',
      'Wo sollte ich als erstes ansetzen?',
      'Welche Quick Wins kann ich sofort umsetzen?',
    ],
    dashboardPrompts: [
      'Was ist der EU AI Act und was bedeutet er fÃ¼r mich?',
      'Wie lÃ¤uft ein Assessment ab?',
      'Was sind die 6 Governance-Dimensionen?',
    ],
    dimensionPrompts: [
      'ErklÃ¤re mir Dimension {dim} im Detail.',
      'Welche Best Practices gibt es fÃ¼r {dim}?',
      'Wie erreiche ich Level 3 in {dim}?',
    ],
    analyzePrompt: 'Bitte analysiere meine Assessment-Ergebnisse. Gib mir eine GesamteinschÃ¤tzung, identifiziere die wichtigsten StÃ¤rken und SchwÃ¤chen, und empfehle konkrete nÃ¤chste Schritte.',
  },
  scoreSlider: {
    level: 'Stufe {n}',
    notRated: 'Nicht bewertet',
  },
  radar: {
    tooltipScore: 'Score',
    radarName: 'Governance-Reifegrad',
    targetLabel: 'Soll (MindestkonformitÃ¤t)',
    bestPractice: 'Best Practice',
  },
  actionPlan: {
    title: 'MaÃŸnahmenplan',
    implementationSteps: 'Umsetzungsschritte',
    quickWinsTitle: 'Quick Wins â€” sofort umsetzbar',
    sourcesTitle: 'WeiterfÃ¼hrende Quellen',
    d1: {
      name: 'Risikomanagement',
      article: 'Art. 9',
      levels: {
        '1to2': {
          target: 'Von Initial zu Managed',
          steps: [
            { title: 'KI-Risikoregister erstellen', description: 'Erstellen Sie eine zentrale Tabelle (z.B. Excel/Notion) mit Spalten: Risiko-ID, Beschreibung, Eintrittswahrscheinlichkeit (1â€“5), Auswirkung (1â€“5), Risiko-Score, Verantwortlicher, Status. Listen Sie zunÃ¤chst mindestens 10 KI-spezifische Risiken auf (z.B. Bias, Drift, Datenlecks, adversariale Angriffe).' },
            { title: 'Risiko-Owner benennen', description: 'Weisen Sie jedem identifizierten Risiko eine verantwortliche Person zu. Diese Person muss nicht alle MaÃŸnahmen selbst umsetzen, aber den Ãœberblick behalten und regelmÃ¤ÃŸig berichten.' },
            { title: 'Erste Risikobewertung durchfÃ¼hren', description: 'FÃ¼hren Sie einen Workshop mit den relevanten Stakeholdern durch. Nutzen Sie eine einfache Risikomatrix (Wahrscheinlichkeit Ã— Schwere) und priorisieren Sie die Top-5-Risiken fÃ¼r sofortige Behandlung.' },
            { title: 'Grundlegende MaÃŸnahmen definieren', description: 'Definieren Sie fÃ¼r die Top-5-Risiken jeweils mindestens eine GegenmaÃŸnahme. Dokumentieren Sie: Was wird getan? Wer ist verantwortlich? Bis wann? Wie wird die Wirksamkeit gemessen?' },
          ],
          quickWins: [
            'KI-Risiko-Template herunterladen und befÃ¼llen',
            'Monatliches 30-min Risiko-Review im Team einfÃ¼hren',
            'Risikokategorien aus ISO 31000 als Vorlage nutzen',
          ],
        },
        '2to3': {
          target: 'Von Managed zu Defined',
          steps: [
            { title: 'Formales KI-RMS dokumentieren', description: 'Erstellen Sie ein schriftliches KI-Risikomanagement-Handbuch mit: Geltungsbereich, Rollen & Verantwortlichkeiten, Risikobewertungsmethodik (z.B. FMEA fÃ¼r KI), Eskalationsprozesse, Review-Zyklen. Orientieren Sie sich an ISO/IEC 23894 (KI-Risikomanagement).' },
            { title: 'Lebenszyklusabdeckung sicherstellen', description: 'Stellen Sie sicher, dass Risiken in jeder Phase identifiziert werden: Design, Datenerhebung, Training, Validierung, Deployment, Betrieb, Dekommissionierung. Nutzen Sie Checklisten fÃ¼r jede Phase.' },
            { title: 'Risikobehandlungsplan erstellen', description: 'Erstellen Sie einen systematischen Plan mit MaÃŸnahmen (Vermeiden, Mindern, Ãœbertragen, Akzeptieren) und dokumentierten Restrisiko-Akzeptanzkriterien. Definieren Sie explizite Schwellwerte, ab denen ein Risiko nicht akzeptabel ist.' },
            { title: 'Testverfahren implementieren', description: 'Definieren Sie regelmÃ¤ÃŸige Testverfahren: Robustheitstests, Fairness-Tests, Stresstests. Dokumentieren Sie TestplÃ¤ne, -ergebnisse und daraus abgeleitete MaÃŸnahmen.' },
          ],
          quickWins: [
            'ISO/IEC 23894 als Rahmenwerk adaptieren',
            'Quartalsweise Risk-Review-Meetings einfÃ¼hren',
            'Risikobehandlungsmatrix mit RACI-Zuordnung erstellen',
          ],
        },
        '3to4': {
          target: 'Von Defined zu Measured',
          steps: [
            { title: 'KPIs fÃ¼r Risikomanagement definieren', description: 'Definieren Sie messbare Indikatoren: Anzahl identifizierter Risiken, durchschnittliche Time-to-Mitigation, Anteil behandelter vs. offener Risiken, Abweichungsrate bei Risikobewertungen. Visualisieren Sie diese in einem Dashboard.' },
            { title: 'Quantitative Risikoanalyse einfÃ¼hren', description: 'ErgÃ¤nzen Sie die qualitative Bewertung um statistische Methoden: Monte-Carlo-Simulationen fÃ¼r Impact-Analysen, Bayessche Netze fÃ¼r AbhÃ¤ngigkeiten zwischen Risiken, SensitivitÃ¤tsanalysen.' },
            { title: 'Automatisiertes Monitoring aufbauen', description: 'Implementieren Sie automatisierte Schwellwert-Ãœberwachung fÃ¼r die wichtigsten Risikoindikatoren. Setzen Sie Alerting-Mechanismen fÃ¼r SchwellwertÃ¼berschreitungen auf.' },
            { title: 'Wirksamkeitsmessung etablieren', description: 'Messen Sie systematisch, ob eingefÃ¼hrte MaÃŸnahmen die Risiken tatsÃ¤chlich reduzieren. Nutzen Sie Vorher-Nachher-Vergleiche und statistische Tests.' },
          ],
          quickWins: [
            'Risiko-Dashboard mit Top-10 KPIs aufsetzen',
            'Automatische Alerts bei SchwellwertÃ¼berschreitungen',
            'WÃ¶chentliche Risiko-Metriken per E-Mail versenden',
          ],
        },
        '4to5': {
          target: 'Von Measured zu Optimizing',
          steps: [
            { title: 'PrÃ¤diktive Risikoidentifikation', description: 'Nutzen Sie ML-basierte Verfahren zur Vorhersage aufkommender Risiken basierend auf historischen Daten, Trendanalysen und externen Signalen (z.B. regulatorische Ã„nderungen, neue Angriffsverfahren).' },
            { title: 'Kontinuierliche Optimierungszyklen', description: 'Implementieren Sie PDCA-Zyklen (Plan-Do-Check-Act) mit datengestÃ¼tzter Entscheidungsfindung. Jeder Zyklus sollte messbare Verbesserungen im Risikoprofil nachweisen kÃ¶nnen.' },
            { title: 'Best-Practice-Sharing', description: 'Etablieren Sie einen Prozess zum Austausch von Lessons Learned innerhalb der Organisation und mit der Community (z.B. Ã¼ber anonymisierte Case Studies, KonferenzbeitrÃ¤ge, Branchenarbeitsgruppen).' },
            { title: 'Echtzeit-Risikosteuerung', description: 'Implementieren Sie Echtzeit-Monitoring mit automatisierter Anpassung der Risikoparameter. Das System sollte selbststÃ¤ndig MaÃŸnahmen eskalieren kÃ¶nnen, wenn Schwellwerte Ã¼berschritten werden.' },
          ],
          quickWins: [
            'Trend-Analyse der letzten 12 Monate Risikodaten',
            'Lessons-Learned-Workshop nach jedem Vorfall',
            'Benchmarking mit Branchenpeergroup',
          ],
        },
        optimizing: {
          target: 'Stufe 5 halten: PrÃ¤emptive MaÃŸnahmen',
          steps: [
            { title: 'Regulatorisches Horizon-Scanning', description: 'Verfolgen Sie aktiv regulatorische Entwicklungen (EU AI Act DurchfÃ¼hrungsrechtsakte, neue Harmonisierungsnormen, Leitlinien der nationalen AufsichtsbehÃ¶rden) und antizipieren Sie deren Auswirkungen auf Ihr Risikomanagementsystem.' },
            { title: 'BranchenÃ¼bergreifendes Benchmarking', description: 'Vergleichen Sie Ihr RMS regelmÃ¤ÃŸig mit Best-in-Class-AnsÃ¤tzen aus anderen Branchen. Adaptieren Sie bewÃ¤hrte Praktiken aus verwandten Bereichen (z.B. Medizinprodukte, Luftfahrt, Nuklearsicherheit).' },
            { title: 'Innovationsrisiken proaktiv bewerten', description: 'Evaluieren Sie neue KI-Technologien (Foundation Models, multimodale Systeme) vor der EinfÃ¼hrung systematisch auf neue Risikokategorien und passen Sie Ihr RMS proaktiv an.' },
          ],
          quickWins: [
            'Regulatorischen Newsletter abonnieren (z.B. AI Act Observer)',
            'JÃ¤hrliches externes Audit des RMS durchfÃ¼hren',
            'Forschungskooperation mit Hochschule aufbauen',
          ],
        },
      },
      sources: [
        { title: 'EU AI Act â€” Art. 9 Risikomanagementsystem (Volltext)', url: 'https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:32024R1689' },
        { title: 'ISO/IEC 23894:2023 â€” KI-Risikomanagement', url: 'https://www.iso.org/standard/77304.html' },
        { title: 'NIST AI Risk Management Framework', url: 'https://www.nist.gov/artificial-intelligence/ai-risk-management-framework' },
        { title: 'BSI â€” Leitfaden KI-Risikobewertung', url: 'https://www.bsi.bund.de/DE/Themen/Unternehmen-und-Organisationen/Informationen-und-Empfehlungen/Kuenstliche-Intelligenz/kuenstliche-intelligenz_node.html' },
      ],
    },
    d2: {
      name: 'Data Governance',
      article: 'Art. 10',
      levels: {
        '1to2': {
          target: 'Von Initial zu Managed',
          steps: [
            { title: 'Dateninventar erstellen', description: 'Erstellen Sie eine Ãœbersicht aller verwendeten DatensÃ¤tze: Quelle, Umfang, Erhebungszeitraum, Personenbezug, Nutzungszweck. Nutzen Sie ein einfaches Spreadsheet als Data Catalog.' },
            { title: 'Grundlegende QualitÃ¤tsprÃ¼fungen einfÃ¼hren', description: 'Implementieren Sie automatisierte Checks auf: fehlende Werte, Duplikate, AusreiÃŸer, Datentyp-Konsistenz. Tools wie Great Expectations oder pandas-profiling erleichtern den Einstieg.' },
            { title: 'DSGVO-Grundlagen sicherstellen', description: 'PrÃ¼fen Sie fÃ¼r jeden Datensatz: Rechtsgrundlage, Zweckbindung, LÃ¶schfristen, AuskunftsfÃ¤higkeit. Dokumentieren Sie dies in einem Verarbeitungsverzeichnis (Art. 30 DSGVO).' },
          ],
          quickWins: [
            'Data-Profiling-Report fÃ¼r jeden Datensatz generieren',
            'Verarbeitungsverzeichnis nach Art. 30 DSGVO anlegen',
            'Grundlegende Datenvalidierungsregeln automatisieren',
          ],
        },
        '2to3': {
          target: 'Von Managed zu Defined',
          steps: [
            { title: 'DatenqualitÃ¤tsstandards dokumentieren', description: 'Definieren Sie messbare QualitÃ¤tskriterien: VollstÃ¤ndigkeit (>95%), AktualitÃ¤t (<30 Tage), Konsistenz (0% WidersprÃ¼che), Genauigkeit (Stichprobenvalidierung). Dokumentieren Sie Schwellwerte und Eskalationsprozesse.' },
            { title: 'Bias-Analyse systematisieren', description: 'Implementieren Sie Fairness-Metriken (Demographic Parity, Equalized Odds, etc.) als Teil der Datenpipeline. FÃ¼hren Sie Bias-Audits fÃ¼r alle TrainingsdatensÃ¤tze durch.' },
            { title: 'Data Lineage einfÃ¼hren', description: 'Dokumentieren Sie den vollstÃ¤ndigen Lebenszyklus jedes Datensatzes: Herkunft â†’ Aufbereitung â†’ Transformation â†’ Verwendung â†’ Archivierung. Tools wie Apache Atlas oder OpenLineage unterstÃ¼tzen die Automatisierung.' },
            { title: 'Privacy-by-Design implementieren', description: 'Integrieren Sie Datenschutz in die Datenpipeline: Pseudonymisierung, Datenanonymisierung, Zugriffskontrollen, Audit-Logging. FÃ¼hren Sie DPIAs (Datenschutz-FolgenabschÃ¤tzungen) fÃ¼r KI-Systeme durch.' },
          ],
          quickWins: [
            'Fairness-Dashboard fÃ¼r Trainingsdaten aufsetzen',
            'Automatisierte DatenqualitÃ¤ts-Checks in CI/CD-Pipeline',
            'DPIA-Template fÃ¼r KI-Systeme erstellen',
          ],
        },
        '3to4': {
          target: 'Von Defined zu Measured',
          steps: [
            { title: 'Automatisiertes QualitÃ¤tsmonitoring', description: 'Implementieren Sie Dashboards, die DatenqualitÃ¤tsmetriken in Echtzeit anzeigen: Drift-Erkennung bei Eingabedaten, QualitÃ¤tstrends, Anomalie-Detektion. Setzen Sie automatische Alerts bei QualitÃ¤tsverletzungen.' },
            { title: 'Automatisierte Bias-Erkennung', description: 'Integrieren Sie Fairness-Checks als automatisierte Tests in Ihre ML-Pipeline. Jedes Modell-Update sollte automatisch auf Bias geprÃ¼ft werden, bevor es deployed wird.' },
            { title: 'Automatisierte Lineage-Erfassung', description: 'Erfassen Sie Data Lineage automatisch durch Instrumentierung der Datenpipeline. Jede Transformation wird automatisch dokumentiert und visualisiert.' },
          ],
          quickWins: [
            'Great Expectations als Datenvalidierungsframework einfÃ¼hren',
            'Automated Fairness Testing in CI/CD integrieren',
            'DatenqualitÃ¤ts-SLAs mit Datenlieferanten vereinbaren',
          ],
        },
        '4to5': {
          target: 'Von Measured zu Optimizing',
          steps: [
            { title: 'PrÃ¤diktive DatenqualitÃ¤t', description: 'Nutzen Sie ML-Modelle zur Vorhersage von DatenqualitÃ¤tsproblemen, bevor sie auftreten. Trainieren Sie Modelle auf historischen QualitÃ¤tsmetriken, um Degradation vorherzusagen.' },
            { title: 'Automatisierte Bias-Korrektur', description: 'Implementieren Sie automatisierte Resampling-, Reweighting- oder adversariale Debiasing-Verfahren, die bei erkanntem Bias automatisch greifen.' },
            { title: 'Impact-Analyse bei DatenÃ¤nderungen', description: 'Automatisieren Sie die Analyse, welche Modelle und Entscheidungen von Ã„nderungen an DatensÃ¤tzen betroffen sind. Nutzen Sie vollstÃ¤ndige Lineage-Graphen fÃ¼r Impact-Propagation.' },
          ],
          quickWins: [
            'ML-basierte Anomalie-Erkennung auf DatenstrÃ¶men',
            'Automatisierte Re-Training-Trigger bei Daten-Drift',
            'Data-Quality-as-Code in Versionskontrolle',
          ],
        },
        optimizing: {
          target: 'Stufe 5 halten: PrÃ¤emptive MaÃŸnahmen',
          steps: [
            { title: 'Synthetische Daten evaluieren', description: 'PrÃ¼fen Sie den Einsatz von synthetischen Daten zur ErgÃ¤nzung realer Daten, insbesondere fÃ¼r unterreprÃ¤sentierte Gruppen. Validieren Sie die QualitÃ¤t synthetischer Daten systematisch.' },
            { title: 'Federated Learning evaluieren', description: 'PrÃ¼fen Sie datenschutzfreundliche Trainingsverfahren wie Federated Learning oder Differential Privacy fÃ¼r sensible DatensÃ¤tze.' },
          ],
          quickWins: [
            'Data-Governance-Bericht fÃ¼r Stakeholder automatisieren',
            'Benchmark-Teilnahme an Data Quality Challenges',
          ],
        },
      },
      sources: [
        { title: 'EU AI Act â€” Art. 10 Daten und Daten-Governance (Volltext)', url: 'https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:32024R1689' },
        { title: 'DAMA DMBOK â€” Data Management Body of Knowledge', url: 'https://www.dama.org/cpages/body-of-knowledge' },
        { title: 'Google â€” Responsible AI Practices: Fairness', url: 'https://ai.google/responsibility/responsible-ai-practices/' },
        { title: 'EDPB â€” Guidelines on AI and Data Protection', url: 'https://edpb.europa.eu/' },
      ],
    },
    d3: {
      name: 'Dokumentation',
      article: 'Art. 11â€“12',
      levels: {
        '1to2': {
          target: 'Von Initial zu Managed',
          steps: [
            { title: 'Dokumentationstemplate erstellen', description: 'Erstellen Sie ein Template basierend auf Anhang IV des AI Acts: Allgemeine Beschreibung, Systemeigenschaften, Algorithmusbeschreibung, Daten-Beschreibung, Validierungsergebnisse, ÃœberwachungsmaÃŸnahmen. FÃ¼llen Sie es zunÃ¤chst mit dem vorhandenen Wissen.' },
            { title: 'Basis-Logging einrichten', description: 'Implementieren Sie strukturiertes Logging fÃ¼r: Modellinferenz-Anfragen, Systemereignisse, FehlerfÃ¤lle, Nutzungsstatistiken. Verwenden Sie ein gÃ¤ngiges Format (z.B. JSON) und zentralisieren Sie die Logs.' },
            { title: 'Versionierung starten', description: 'FÃ¼hren Sie eine grundlegende Versionierung ein: Git fÃ¼r Code, DVC oder MLflow fÃ¼r Modelle und DatensÃ¤tze. Dokumentieren Sie bei jedem Release die Ã„nderungen in einem Changelog.' },
          ],
          quickWins: [
            'Anhang IV des AI Act als Dokumentationsvorlage nutzen',
            'Strukturiertes JSON-Logging implementieren',
            'Git-basierte Versionierung fÃ¼r alle Artefakte einfÃ¼hren',
          ],
        },
        '2to3': {
          target: 'Von Managed zu Defined',
          steps: [
            { title: 'VollstÃ¤ndige Anhang-IV-Dokumentation', description: 'Stellen Sie sicher, dass alle Punkte aus Anhang IV abgedeckt sind: Systembeschreibung, Designentscheidungen, Trainings- und Testmethodik, Leistungsmetriken, EinschrÃ¤nkungen, ÃœberwachungsplÃ¤ne.' },
            { title: 'Systematisches Event-Logging', description: 'Implementieren Sie umfassendes Logging: alle Entscheidungen des KI-Systems, Input-Daten (Referenzen), Konfidenzwerte, ErklÃ¤rungen, manuelle Overrides, SystemzustÃ¤nde. Stellen Sie Aufbewahrungsfristen sicher.' },
            { title: 'DurchgÃ¤ngige Versionierung aller Artefakte', description: 'Versionieren Sie systematisch: Trainingsdaten, Modellparameter, Konfigurationen, Feature-Engineering-Pipelines, Evaluierungsergebnisse. Jede Modellversion muss reproduzierbar sein.' },
            { title: 'KonformitÃ¤tsnachweise systematisch erstellen', description: 'Erstellen Sie Templates fÃ¼r regulatorische Berichte und KonformitÃ¤tserklÃ¤rungen. Definieren Sie den Erstellungsprozess, verantwortliche Personen und Review-Zyklen.' },
          ],
          quickWins: [
            'MLflow/Weights & Biases fÃ¼r Experiment-Tracking einfÃ¼hren',
            'Log-Retention-Policy definieren und implementieren',
            'Model Card Template fÃ¼r jedes Modell erstellen',
          ],
        },
        '3to4': {
          target: 'Von Defined zu Measured',
          steps: [
            { title: 'Auto-generierte Dokumentation', description: 'Automatisieren Sie die Dokumentationserstellung: Model Cards werden aus Experiment-Tracking generiert, API-Dokumentation aus Code, DatenblÃ¤tter aus Data Profiling.' },
            { title: 'Zentralisiertes Log-Management', description: 'Implementieren Sie eine zentrale Log-Plattform (z.B. ELK Stack, Grafana Loki) mit: Suche, Filterung, Analyse-Dashboards, automatisierte Anomalie-Erkennung in Logs.' },
            { title: 'Automatisierte KonformitÃ¤tsnachweise', description: 'Generieren Sie KonformitÃ¤tsberichte automatisch aus dem System: Testberichte, Performance-Reports, Audit-Trails. Stellen Sie eine lÃ¼ckenlose Nachverfolgbarkeit sicher.' },
          ],
          quickWins: [
            'CI/CD-Pipeline generiert automatisch Model Cards',
            'ELK Stack oder Grafana Loki als Log-Plattform',
            'Automated Compliance Report Generation einrichten',
          ],
        },
        '4to5': {
          target: 'Von Measured zu Optimizing',
          steps: [
            { title: 'Living Documentation', description: 'Implementieren Sie Dokumentation, die sich automatisch aktualisiert, wenn sich das System Ã¤ndert. Validieren Sie automatisch die VollstÃ¤ndigkeit und AktualitÃ¤t.' },
            { title: 'Intelligentes Logging', description: 'Nutzen Sie ML zur Anomalie-Erkennung in Logs, zur automatischen Korrelation von Ereignissen und zur prÃ¤diktiven Warnung vor Systemfehlern.' },
            { title: 'VollstÃ¤ndige Reproduzierbarkeit', description: 'Stellen Sie sicher, dass jede historische Modellversion mit den exakt gleichen Daten, Code und Konfigurationen reproduziert werden kann. Automatisieren Sie Reproduzierbarkeitstests.' },
          ],
          quickWins: [
            'Documentation-as-Code-Ansatz vollstÃ¤ndig umsetzen',
            'Automatisierte Dokumentations-VollstÃ¤ndigkeits-Checks',
            'Reproduzierbarkeitstest als Teil der CI/CD-Pipeline',
          ],
        },
        optimizing: {
          target: 'Stufe 5 halten: PrÃ¤emptive MaÃŸnahmen',
          steps: [
            { title: 'AI Bill of Materials (AI-BOM)', description: 'Erstellen Sie eine maschinenlesbare AI-BOM, die alle Komponenten, AbhÃ¤ngigkeiten und Lizenzen Ihres KI-Systems erfasst â€” analog zur Software-BOM (SBOM).' },
            { title: 'InteroperabilitÃ¤t vorbereiten', description: 'Bereiten Sie Ihre Dokumentation auf zukÃ¼nftige EU-Standardisierung vor. Nutzen Sie offene Formate und Schnittstellen.' },
          ],
          quickWins: [
            'AI-BOM-Prototyp erstellen',
            'CEN/CENELEC AI Standards verfolgen',
          ],
        },
      },
      sources: [
        { title: 'EU AI Act â€” Art. 11â€“12, Anhang IV (Volltext)', url: 'https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:32024R1689' },
        { title: 'Google Model Cards for Model Reporting', url: 'https://modelcards.withgoogle.com/about' },
        { title: 'MLflow â€” Open-Source ML Lifecycle Platform', url: 'https://mlflow.org/' },
        { title: 'OECD â€” Framework for AI System Classification', url: 'https://oecd.ai/en/classification' },
      ],
    },
    d4: {
      name: 'Transparenz',
      article: 'Art. 13',
      levels: {
        '1to2': {
          target: 'Von Initial zu Managed',
          steps: [
            { title: 'Systembeschreibung fÃ¼r Nutzer erstellen', description: 'Schreiben Sie eine verstÃ¤ndliche Beschreibung: Was macht das System? Wie trifft es Entscheidungen? Welche Daten verwendet es? Welche Grenzen hat es? Verwenden Sie klare Sprache, keine technischen Fachbegriffe.' },
            { title: 'KI-Kennzeichnung einfÃ¼hren', description: 'Kennzeichnen Sie an allen BerÃ¼hrungspunkten, wo KI zum Einsatz kommt. Nutzer mÃ¼ssen wissen, wann sie mit einem KI-System interagieren (Art. 50 AI Act fÃ¼r bestimmte Systeme).' },
            { title: 'Grundlegende ErklÃ¤rungen bereitstellen', description: 'Bieten Sie fÃ¼r jede KI-Entscheidung eine kurze ErklÃ¤rung an: Warum wurde so entschieden? Welche Faktoren waren ausschlaggebend? Nutzen Sie einfache Feature-Importance-Darstellungen.' },
          ],
          quickWins: [
            'NutzerverstÃ¤ndliche Systembeschreibung (1 Seite) erstellen',
            'â€žKI-gestÃ¼tzt"-Badge an allen relevanten Stellen anzeigen',
            'Top-3-Einflussfaktoren bei jeder Entscheidung anzeigen',
          ],
        },
        '2to3': {
          target: 'Von Managed zu Defined',
          steps: [
            { title: 'Systematische XAI-Methoden implementieren', description: 'WÃ¤hlen Sie passende ErklÃ¤rbarkeits-Methoden: LIME fÃ¼r lokale ErklÃ¤rungen, SHAP fÃ¼r Feature-Importances, Counterfactual Explanations fÃ¼r Alternativszenarien. Implementieren Sie mindestens zwei komplementÃ¤re Methoden.' },
            { title: 'Informationspflichten nach Art. 13 Abs. 3 erfÃ¼llen', description: 'Stellen Sie bereit: Kontaktdaten des Anbieters, Zweck des Systems, Genauigkeitsmetriken, bekannte Risiken, erforderliche menschliche Aufsicht, erwartete Lebensdauer.' },
            { title: 'FÃ¤higkeiten und Grenzen dokumentieren', description: 'Erstellen Sie eine detaillierte Ãœbersicht: Anwendungsbereich, Leistungsgrenzen, Szenarien mit eingeschrÃ¤nkter ZuverlÃ¤ssigkeit, bekannte SchwÃ¤chen, Bedingungen fÃ¼r optimale FunktionalitÃ¤t.' },
            { title: 'Governance-Prozesse transparent dokumentieren', description: 'Machen Sie Ihre Governance-Prozesse transparent: Wer entscheidet was? Wie werden Beschwerden behandelt? Welche Kontrollmechanismen gibt es?' },
          ],
          quickWins: [
            'SHAP-Plots als Standard-ErklÃ¤rung implementieren',
            'Model Card mit Leistungsgrenzen verÃ¶ffentlichen',
            'Transparenz-Seite auf Website/Intranet erstellen',
          ],
        },
        '3to4': {
          target: 'Von Defined zu Measured',
          steps: [
            { title: 'Zielgruppenspezifische ErklÃ¤rungen', description: 'Differenzieren Sie ErklÃ¤rungen nach Zielgruppe: technisch detailliert fÃ¼r Entwickler, verstÃ¤ndliche Zusammenfassungen fÃ¼r Endnutzer, regulatorisch aufbereitete Berichte fÃ¼r AufsichtsbehÃ¶rden.' },
            { title: 'ErklÃ¤rungsqualitÃ¤t messen', description: 'Messen Sie die QualitÃ¤t Ihrer ErklÃ¤rungen: NutzerverstÃ¤ndnis (Tests), Zufriedenheit (Surveys), Korrektheit (Validierung gegen Ground Truth), Konsistenz.' },
            { title: 'Proaktive, kontextspezifische Information', description: 'Informieren Sie Nutzer proaktiv, wenn sich Systemeigenschaften Ã¤ndern, die Konfidenz niedrig ist oder das System auÃŸerhalb seines optimalen Bereichs operiert.' },
          ],
          quickWins: [
            'ErklÃ¤rungsverstÃ¤ndnis in User Research Tests messen',
            'Konfidenz-Anzeige bei jeder Systemausgabe',
            'Changelog fÃ¼r Nutzer bei System-Updates',
          ],
        },
        '4to5': {
          target: 'Von Measured zu Optimizing',
          steps: [
            { title: 'Adaptive ErklÃ¤rbarkeit', description: 'Passen Sie ErklÃ¤rungen automatisch an den Wissensstand und die BedÃ¼rfnisse des jeweiligen Nutzers an. Nutzen Sie Feedback-Loops, um ErklÃ¤rungen kontinuierlich zu verbessern.' },
            { title: 'Interaktive Informationssysteme', description: 'ErmÃ¶glichen Sie Nutzern, interaktiv zu explorieren: What-If-Analysen, Vergleichsszenarien, detaillierte AufschlÃ¼sselungen. Implementieren Sie Conversational XAI.' },
          ],
          quickWins: [
            'Nutzer-Feedback zu ErklÃ¤rungen systematisch auswerten',
            'Interactive Explorer fÃ¼r Modellentscheidungen prototypen',
          ],
        },
        optimizing: {
          target: 'Stufe 5 halten: PrÃ¤emptive MaÃŸnahmen',
          steps: [
            { title: 'Transparenz-Benchmarks etablieren', description: 'Vergleichen Sie Ihre TransparenzmaÃŸnahmen mit Branchenstandards. Publizieren Sie einen jÃ¤hrlichen Transparenzbericht.' },
            { title: 'Regulatorische Entwicklungen antizipieren', description: 'Verfolgen Sie die Entwicklung von Harmonisierungsnormen zu Art. 13 und passen Sie Ihre TransparenzmaÃŸnahmen proaktiv an.' },
          ],
          quickWins: [
            'JÃ¤hrlichen KI-Transparenzbericht verÃ¶ffentlichen',
            'Nutzerbeirat fÃ¼r Transparenz-Feedback einrichten',
          ],
        },
      },
      sources: [
        { title: 'EU AI Act â€” Art. 13 Transparenz (Volltext)', url: 'https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:32024R1689' },
        { title: 'SHAP â€” SHapley Additive exPlanations', url: 'https://shap.readthedocs.io/' },
        { title: 'LIME â€” Local Interpretable Model-agnostic Explanations', url: 'https://github.com/marcotcr/lime' },
        { title: 'AlgorithmWatch â€” Automatisierte Entscheidungssysteme', url: 'https://algorithmwatch.org/de/' },
      ],
    },
    d5: {
      name: 'Menschliche Aufsicht',
      article: 'Art. 14',
      levels: {
        '1to2': {
          target: 'Von Initial zu Managed',
          steps: [
            { title: 'Human-in-the-Loop identifizieren', description: 'Bestimmen Sie, an welchen Stellen menschliche Aufsicht erforderlich ist. Unterscheiden Sie: HITL (Human-in-the-Loop, Mensch entscheidet), HOTL (Human-on-the-Loop, Mensch Ã¼berwacht), HOCL (Human-out-of-Command, Mensch kann eingreifen).' },
            { title: 'Notfall-Abschaltung bereitstellen', description: 'Implementieren Sie eine sofort zugÃ¤ngliche MÃ¶glichkeit, das KI-System zu stoppen oder zu deaktivieren. Dokumentieren Sie den Prozess und stellen Sie sicher, dass er ohne technisches Spezialwissen nutzbar ist.' },
            { title: 'Grundlegende Schulung durchfÃ¼hren', description: 'Schulen Sie alle Aufsichtspersonen in: SystemfunktionalitÃ¤t, Grenzen des Systems, Erkennungsmerkmale fÃ¼r Fehler, Eskalationswege, Nutzung der Abschaltmechanismen.' },
          ],
          quickWins: [
            'HITL/HOTL/HOCL-Zuordnung fÃ¼r alle KI-Entscheidungen',
            'Kill-Switch und Dokumentation bereitstellen',
            'Basis-Schulung fÃ¼r Aufsichtspersonen (2h) entwickeln',
          ],
        },
        '2to3': {
          target: 'Von Managed zu Defined',
          steps: [
            { title: 'Aufsichtskonzept systematisieren', description: 'Dokumentieren Sie ein formales Aufsichtskonzept: Wer Ã¼berwacht wann? Welche Informationen stehen zur VerfÃ¼gung? Welche Entscheidungen dÃ¼rfen automatisiert sein? Wie erfolgt die Eskalation?' },
            { title: 'Kompetenzprofile definieren', description: 'Erstellen Sie Kompetenzprofile fÃ¼r Aufsichtspersonen: technisches VerstÃ¤ndnis, DomÃ¤nenwissen, Kenntnisse Ã¼ber Systemgrenzen, ethische Kompetenz. Definieren Sie Schulungsprogramme.' },
            { title: 'Eskalations- und Interventionsprozesse', description: 'Definieren Sie klare Prozesse: Bei welchen Signalen wird eskaliert? An wen? In welchem Zeitrahmen? Wie werden Korrekturen dokumentiert? Wie wird die Wirksamkeit validiert?' },
            { title: 'Automation-Bias-PrÃ¤vention', description: 'Implementieren Sie systematische MaÃŸnahmen: Decision-Support statt Decision-Making, regelmÃ¤ÃŸige KalibrierungsÃ¼bungen, DiversitÃ¤t in Aufsichtsteams, Pflicht zur eigenstÃ¤ndigen PrÃ¼fung vor BestÃ¤tigung.' },
          ],
          quickWins: [
            'Aufsichtskonzept als Dokument formalisieren',
            'Monatliche KalibrierungsÃ¼bung fÃ¼r Aufsichtspersonen',
            'Automation-Bias-Awareness-Training (halbjÃ¤hrlich)',
          ],
        },
        '3to4': {
          target: 'Von Defined zu Measured',
          steps: [
            { title: 'Override-Rate und -QualitÃ¤t messen', description: 'Erfassen und analysieren Sie systematisch: Wie oft greifen Aufsichtspersonen ein? War der Eingriff korrekt? Wie lange dauert die Reaktionszeit? Erkennen Aufsichtspersonen Fehler zuverlÃ¤ssig?' },
            { title: 'Automatisierte Interventionsmechanismen', description: 'Implementieren Sie automatische Schwellwert-basierte Interventionen: System pausiert bei niedriger Konfidenz, eskaliert bei ungewÃ¶hnlichen Eingaben, alertet bei Drift.' },
            { title: 'Bias-PrÃ¤ventions-EffektivitÃ¤t messen', description: 'Messen Sie, ob Ihre MaÃŸnahmen gegen Automation Bias wirken: Vergleichen Sie Override-Raten vor und nach Schulungen, messen Sie die Korrektheit von Override-Entscheidungen.' },
          ],
          quickWins: [
            'Override-Dashboard mit Trendanalyse aufsetzen',
            'Automatische Pausierung bei Konfidenz < Schwellwert',
            'VierteljÃ¤hrliche Analyse der Override-QualitÃ¤t',
          ],
        },
        '4to5': {
          target: 'Von Measured zu Optimizing',
          steps: [
            { title: 'Adaptive Aufsichtsmechanismen', description: 'Passen Sie den Grad menschlicher Aufsicht dynamisch an: mehr Aufsicht bei unbekannten Szenarien, weniger bei gut verstandenen. Nutzen Sie Conformal Prediction fÃ¼r kalibrierte UnsicherheitsschÃ¤tzungen.' },
            { title: 'PrÃ¤diktive Eskalation', description: 'Implementieren Sie Systeme, die potenzielle Probleme vorhersagen und proaktiv eskalieren, bevor sie eintreten. Nutzen Sie Muster aus historischen Override-Daten.' },
          ],
          quickWins: [
            'Dynamische HITL-Schwellwerte basierend auf Konfidenz',
            'Lernende Eskalation aus historischen Daten',
          ],
        },
        optimizing: {
          target: 'Stufe 5 halten: PrÃ¤emptive MaÃŸnahmen',
          steps: [
            { title: 'Mensch-Maschine-Teaming erforschen', description: 'Evaluieren Sie neue AnsÃ¤tze fÃ¼r optimale Aufgabenteilung zwischen Mensch und KI. Nutzen Sie Forschungsergebnisse aus der Human-AI Interaction Forschung.' },
            { title: 'Cognitive Load Management', description: 'Optimieren Sie die kognitive Belastung der Aufsichtspersonen: InformationsprÃ¤sentation, Alert-Fatigue-PrÃ¤vention, Aufgabenrotation.' },
          ],
          quickWins: [
            'Alert-Fatigue-Analyse durchfÃ¼hren und Alerts priorisieren',
            'Ergonomie-Review der Aufsichtstools durchfÃ¼hren',
          ],
        },
      },
      sources: [
        { title: 'EU AI Act â€” Art. 14 Menschliche Aufsicht (Volltext)', url: 'https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:32024R1689' },
        { title: 'ISO/IEC TR 24028 â€” AI Trustworthiness', url: 'https://www.iso.org/standard/77608.html' },
        { title: 'Stanford HAI â€” Human-Centered AI', url: 'https://hai.stanford.edu/' },
        { title: 'EU HLEG â€” Ethics Guidelines for Trustworthy AI', url: 'https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai' },
      ],
    },
    d6: {
      name: 'Technische Robustheit',
      article: 'Art. 15',
      levels: {
        '1to2': {
          target: 'Von Initial zu Managed',
          steps: [
            { title: 'Baseline-Metriken definieren', description: 'Definieren Sie grundlegende Leistungsmetriken: Accuracy, Precision, Recall, F1-Score (Klassifikation) oder MAE, RMSE (Regression). Messen Sie diese auf einem separaten Testdatensatz und dokumentieren Sie die Ergebnisse.' },
            { title: 'Grundlegende Fehlerbehandlung', description: 'Implementieren Sie robuste Fehlerbehandlung: Graceful Degradation bei fehlenden Eingaben, aussagekrÃ¤ftige Fehlermeldungen, Fallback auf regelbasierte Systeme bei Systemausfall.' },
            { title: 'IT-Sicherheitsbasislinie', description: 'Stellen Sie sicher, dass Standard-IT-SicherheitsmaÃŸnahmen angewendet werden: Zugriffskontrollen, VerschlÃ¼sselung, regelmÃ¤ÃŸige Updates, Netzwerksegmentierung fÃ¼r das KI-System.' },
          ],
          quickWins: [
            'Test-Set-Performance dokumentieren und versionieren',
            'Fallback-Meldung bei Systemausfall implementieren',
            'Zugriff auf KI-System auf autorisierte Nutzer beschrÃ¤nken',
          ],
        },
        '2to3': {
          target: 'Von Managed zu Defined',
          steps: [
            { title: 'Umfassende Metriken mit Schwellwerten', description: 'Erweitern Sie Ihre Metriken: Fairness-Metriken pro Subgruppe, Kalibrierung, Robustheit gegen Rauschen, Latenz-Metriken. Definieren Sie Minimal-Schwellwerte, bei deren Unterschreitung das System nicht deployed werden darf.' },
            { title: 'Systematische Robustheitstests', description: 'Implementieren Sie: Adversariale Tests (FGSM, PGD), Perturbationstests, Stresstests mit Extremwerten, Out-of-Distribution-Detection. Integrieren Sie diese in Ihre CI/CD-Pipeline.' },
            { title: 'KI-spezifische SicherheitsmaÃŸnahmen', description: 'Implementieren Sie: Input-Validierung gegen adversariale Eingaben, Model Integrity Checks (Hash-Validierung), Schutz vor Model Extraction, Monitoring fÃ¼r ungewÃ¶hnliche Query-Muster.' },
            { title: 'Monitoring und Drift-Erkennung', description: 'Setzen Sie automatisiertes Monitoring auf: Data Drift (PSI, KS-Test), Concept Drift (Performance-Degradation), Feature Drift. Definieren Sie Schwellwerte und Alerting.' },
            { title: 'Fallback-Mechanismen definieren', description: 'Definieren Sie gestufte Fallback-Prozesse: Warnung â†’ EinschrÃ¤nkung â†’ Regelbasierter Fallback â†’ Manueller Prozess â†’ Systemabschaltung. Testen Sie diese regelmÃ¤ÃŸig.' },
          ],
          quickWins: [
            'Adversarial Robustness Toolbox (ART) einsetzen',
            'PSI/KS-Test fÃ¼r Data Drift als Cronjob einrichten',
            'Fallback-Prozess dokumentieren und jÃ¤hrlich testen',
          ],
        },
        '3to4': {
          target: 'Von Defined zu Measured',
          steps: [
            { title: 'Echtzeit-Performance-Monitoring', description: 'Implementieren Sie Dashboards mit Echtzeit-Metriken: Inferenz-Latenz, Throughput, Error-Rate, Drift-Indikatoren, Anomalie-Scores. Setzen Sie automatische Alerts bei SchwellwertÃ¼berschreitungen.' },
            { title: 'Red-Teaming und Penetrationstests', description: 'FÃ¼hren Sie regelmÃ¤ÃŸige adversariale Sicherheitstests durch: Model Inversion, Membership Inference, Data Poisoning Simulationen. Dokumentieren Sie Findings und Remediations.' },
            { title: 'Automatisiertes Fallback-Testing', description: 'Testen Sie Fallback-Mechanismen automatisiert: Chaos Engineering fÃ¼r KI (zufÃ¤lliges Injizieren von Fehlern), Load Testing, Failover-Tests.' },
          ],
          quickWins: [
            'Grafana/Prometheus fÃ¼r KI-Metriken-Dashboard',
            'QuartalmÃ¤ÃŸiges Red-Teaming einfÃ¼hren',
            'Chaos-Engineering-Tests fÃ¼r Fallback-Validierung',
          ],
        },
        '4to5': {
          target: 'Von Measured zu Optimizing',
          steps: [
            { title: 'PrÃ¤diktives Monitoring', description: 'Implementieren Sie ML-basiertes Monitoring, das Performance-Degradation vorhersagt, bevor sie eintritt. Nutzen Sie Time-Series-Forecasting auf Metriken-Daten.' },
            { title: 'Automatische Modell-Aktualisierung', description: 'Implementieren Sie sichere, automatisierte Retraining-Pipelines: Trigger bei Drift-Erkennung, automatisierte Validierung, Canary Deployments, automatisierter Rollback.' },
            { title: 'Resiliente Architektur', description: 'Implementieren Sie selbstheilende Mechanismen: automatischer Failover, Load Balancing, Circuit Breaker Pattern, automatische Skalierung bei Last.' },
          ],
          quickWins: [
            'Time-Series-Forecasting auf Performance-Metriken',
            'Canary Deployment fÃ¼r Modell-Updates',
            'Circuit Breaker Pattern fÃ¼r externe AbhÃ¤ngigkeiten',
          ],
        },
        optimizing: {
          target: 'Stufe 5 halten: PrÃ¤emptive MaÃŸnahmen',
          steps: [
            { title: 'Emerging Threats verfolgen', description: 'Verfolgen Sie aktiv neue Bedrohungen fÃ¼r KI-Systeme: neue adversariale Angriffstechniken, Supply-Chain-Risiken bei ML-Modellen, SicherheitslÃ¼cken in ML-Frameworks.' },
            { title: 'Zero-Trust fÃ¼r KI vorantreiben', description: 'Erweitern Sie Zero-Trust-Prinzipien auf KI-Komponenten: jede Modellvorhersage wird validiert, jeder Input wird geprÃ¼ft, keine implizite Vertrauensstellung.' },
          ],
          quickWins: [
            'ML Security Newsletter/Feed abonnieren',
            'Dependency-Scanning fÃ¼r ML-Packages automatisieren',
          ],
        },
      },
      sources: [
        { title: 'EU AI Act â€” Art. 15 Genauigkeit, Robustheit, Cybersicherheit (Volltext)', url: 'https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:32024R1689' },
        { title: 'ENISA â€” Securing Machine Learning Algorithms', url: 'https://www.enisa.europa.eu/publications/securing-machine-learning-algorithms' },
        { title: 'IBM Adversarial Robustness Toolbox (ART)', url: 'https://github.com/Trusted-AI/adversarial-robustness-toolbox' },
        { title: 'MITRE ATLAS â€” Adversarial Threat Landscape for AI', url: 'https://atlas.mitre.org/' },
      ],
    },
  },
  dimensions: {
    D1: {
      name: 'Risikomanagement',
      description: 'Einrichtung und Pflege eines KI-spezifischen Risikomanagementsystems Ã¼ber den gesamten Lebenszyklus â€” von systematischer Identifikation Ã¼ber Bewertung bis zur kontinuierlichen Validierung gemÃ¤ÃŸ Art. 9.',
      criteria: {
        'D1.1': { name: 'KI-spezifisches Risikomanagementsystem', question: 'Existiert ein dokumentiertes, KI-spezifisches Risikomanagementsystem in Ihrer Organisation?', indicators: { '1': 'Kein formales Risikomanagementsystem vorhanden', '2': 'Grundlegende Risikobetrachtung, aber nicht KI-spezifisch', '3': 'Dokumentiertes KI-Risikomanagementsystem mit definierten Prozessen', '4': 'Systematisch gemessenes und Ã¼berwachtes Risikomanagementsystem mit KPIs', '5': 'Kontinuierlich optimiertes System mit Best-Practice-Sharing' } },
        'D1.2': { name: 'Systematische Risikoidentifikation', question: 'Erfolgt eine systematische Risikoidentifikation Ã¼ber den gesamten KI-Lebenszyklus?', indicators: { '1': 'Ad-hoc Risikoidentifikation', '2': 'Risikoidentifikation in einzelnen Phasen', '3': 'Systematische Risikoidentifikation Ã¼ber alle Lebenszyklusphasen', '4': 'Quantitative Risikoanalysen mit definierten Metriken', '5': 'PrÃ¤diktive Risikoidentifikation mit kontinuierlicher Anpassung' } },
        'D1.3': { name: 'Risikobewertungsmethodik', question: 'Welche Methodik wird fÃ¼r die Risikobewertung eingesetzt?', indicators: { '1': 'Keine formale Methodik', '2': 'Einfache qualitative Bewertung', '3': 'Dokumentierte Methodik (Wahrscheinlichkeit Ã— Schwere)', '4': 'Quantitative Bewertung mit statistischen Methoden', '5': 'Fortgeschrittene Methoden mit szenariobasierter Analyse' } },
        'D1.4': { name: 'Risikobehandlung und Restrisiko', question: 'Sind RisikobehandlungsmaÃŸnahmen und Restrisiko-Akzeptanzkriterien definiert?', indicators: { '1': 'Keine definierten MaÃŸnahmen', '2': 'Einzelne MaÃŸnahmen ohne systematische Zuordnung', '3': 'Definierte MaÃŸnahmen mit dokumentierter Restrisiko-Akzeptanz', '4': 'Systematisches MaÃŸnahmentracking mit Wirksamkeitsmessung', '5': 'Optimierte Risikobehandlung mit automatisierter Ãœberwachung' } },
        'D1.5': { name: 'Testverfahren zur Risikovalidierung', question: 'Werden regelmÃ¤ÃŸige Testverfahren zur Validierung der Risikobewertungen durchgefÃ¼hrt?', indicators: { '1': 'Keine Testverfahren', '2': 'Gelegentliche manuelle Tests', '3': 'RegelmÃ¤ÃŸige, dokumentierte Testverfahren', '4': 'Automatisierte Testsuiten mit definierten Schwellwerten', '5': 'Kontinuierliche Testpipeline mit Regressionstests' } },
        'D1.6': { name: 'Kontinuierliche Aktualisierung', question: 'Wird das Risikomanagementsystem kontinuierlich aktualisiert?', indicators: { '1': 'Keine Aktualisierung', '2': 'Anlassbezogene Aktualisierung', '3': 'RegelmÃ¤ÃŸige Review-Zyklen (z.B. quartalsweise)', '4': 'Ereignisgesteuerte plus regelmÃ¤ÃŸige Aktualisierung mit Metriken', '5': 'Echtzeit-Monitoring mit automatisierter Anpassung' } },
      },
    },
    D2: {
      name: 'Data Governance',
      description: 'QualitÃ¤tssicherung von Trainings-, Validierungs- und Testdaten einschlieÃŸlich Bias-Erkennung, Datenherkunftsnachverfolgung und DSGVO-konformer Daten-Governance gemÃ¤ÃŸ Art. 10.',
      criteria: {
        'D2.1': { name: 'DatenqualitÃ¤tsstandards', question: 'Existieren definierte DatenqualitÃ¤tskriterien fÃ¼r KI-Trainings-, Validierungs- und Testdaten?', indicators: { '1': 'Keine DatenqualitÃ¤tsstandards', '2': 'Grundlegende QualitÃ¤tsprÃ¼fungen', '3': 'Dokumentierte Standards mit definierten Metriken', '4': 'Automatisierte QualitÃ¤tsÃ¼berwachung mit Dashboards', '5': 'PrÃ¤diktive QualitÃ¤tssicherung mit kontinuierlicher Optimierung' } },
        'D2.2': { name: 'Bias-Erkennung und -Korrektur', question: 'Existieren systematische Verfahren zur Erkennung und Minimierung von Verzerrungen?', indicators: { '1': 'Keine Bias-PrÃ¼fung', '2': 'Manuelle PrÃ¼fung einzelner DatensÃ¤tze', '3': 'Systematische Bias-Analyse mit definierten Methoden', '4': 'Automatisierte Bias-Erkennung mit Fairness-Metriken', '5': 'Kontinuierliches Bias-Monitoring mit automatischer Korrektur' } },
        'D2.3': { name: 'Data Lineage', question: 'Ist die Datenherkunft, -aufbereitung und -nutzung dokumentiert?', indicators: { '1': 'Keine Dokumentation', '2': 'Teilweise Dokumentation der Datenquellen', '3': 'VollstÃ¤ndige Data-Lineage-Dokumentation', '4': 'Automatisierte Lineage-Erfassung mit Visualisierung', '5': 'DurchgÃ¤ngige Lineage mit Impact-Analyse' } },
        'D2.4': { name: 'Datenschutz-Integration', question: 'Sind Datenschutzanforderungen (DSGVO) in die Data Governance integriert?', indicators: { '1': 'Keine Integration', '2': 'Grundlegende DSGVO-MaÃŸnahmen', '3': 'Systematische Integration mit Privacy-by-Design', '4': 'Automatisierte Compliance-PrÃ¼fung mit Auditing', '5': 'Proaktive Datenschutz-Governance mit Impact Assessments' } },
        'D2.5': { name: 'Kontinuierliche DatenqualitÃ¤tssicherung', question: 'Existieren Zyklen zur kontinuierlichen DatenqualitÃ¤tssicherung?', indicators: { '1': 'Keine kontinuierliche Sicherung', '2': 'Reaktive QualitÃ¤tskorrekturen', '3': 'RegelmÃ¤ÃŸige QualitÃ¤tsreviews', '4': 'Proaktive QualitÃ¤tssicherung mit Monitoring', '5': 'Automatisierte QualitÃ¤tsoptimierung mit ML-gestÃ¼tzter Erkennung' } },
      },
    },
    D3: {
      name: 'Dokumentation',
      description: 'VollstÃ¤ndige technische Dokumentation gemÃ¤ÃŸ Anhang IV sowie automatisierte Ereignisprotokollierung, Versionierung und NachweisfÃ¼hrung gemÃ¤ÃŸ Art. 11â€“12.',
      criteria: {
        'D3.1': { name: 'Technische Dokumentation', question: 'Ist die technische Dokumentation vollstÃ¤ndig und aktuell?', indicators: { '1': 'Keine oder minimale Dokumentation', '2': 'Grundlegende Dokumentation, nicht aktuell', '3': 'VollstÃ¤ndige, aktuelle Dokumentation gemÃ¤ÃŸ Anhang IV', '4': 'Automatisiert generierte und aktualisierte Dokumentation', '5': 'Living Documentation mit automatischer Validierung' } },
        'D3.2': { name: 'Automatisiertes Logging', question: 'Sind Systeme zur automatisierten Aufzeichnung von Systemereignissen implementiert?', indicators: { '1': 'Kein Logging', '2': 'Grundlegendes Logging ohne Struktur', '3': 'Strukturiertes Logging aller relevanten Ereignisse', '4': 'Zentralisiertes Logging mit Analyse-Tools', '5': 'Intelligentes Logging mit automatisierter Anomalie-Erkennung' } },
        'D3.3': { name: 'Versionierung', question: 'Ist eine durchgÃ¤ngige Versionierung und Ã„nderungsnachverfolgung implementiert?', indicators: { '1': 'Keine Versionierung', '2': 'Manuelle Versionierung einzelner Komponenten', '3': 'Systematische Versionierung aller Artefakte', '4': 'Automatisierte Versionierung mit AbhÃ¤ngigkeitsmanagement', '5': 'VollstÃ¤ndige Reproduzierbarkeit aller Modellversionen' } },
        'D3.4': { name: 'KonformitÃ¤tsnachweise', question: 'Werden KonformitÃ¤tsnachweise und regulatorische Berichte systematisch erstellt?', indicators: { '1': 'Keine KonformitÃ¤tsnachweise', '2': 'Ad-hoc erstellte Nachweise', '3': 'Systematische Erstellung gemÃ¤ÃŸ regulatorischer Anforderungen', '4': 'Automatisierte Nachweiserstellung mit Audit-Trail', '5': 'Proaktive Compliance-Berichterstattung mit FrÃ¼hwarnung' } },
        'D3.5': { name: 'Dokumentationsverwaltung', question: 'Wie wird die ZugÃ¤nglichkeit und Verwaltung der Dokumentation sichergestellt?', indicators: { '1': 'Unstrukturierte Ablage', '2': 'Zentrale Ablage ohne Zugriffsmanagement', '3': 'Strukturiertes DMS mit Zugriffsrechten', '4': 'Integriertes DMS mit Workflow-UnterstÃ¼tzung', '5': 'KI-gestÃ¼tztes Wissensmanagement mit automatischer Klassifikation' } },
      },
    },
    D4: {
      name: 'Transparenz',
      description: 'ErklÃ¤rbarkeit von KI-Entscheidungen, Informationspflichten gegenÃ¼ber Nutzern, Kennzeichnung KI-generierter Inhalte und Prozesstransparenz gemÃ¤ÃŸ Art. 13.',
      criteria: {
        'D4.1': { name: 'ErklÃ¤rbarkeit', question: 'Wie wird die ErklÃ¤rbarkeit der SystemfunktionalitÃ¤t und Entscheidungslogik sichergestellt?', indicators: { '1': 'Keine ErklÃ¤rbarkeitsmaÃŸnahmen', '2': 'Grundlegende Modellbeschreibung', '3': 'Systematische ErklÃ¤rbarkeit mit definierten Methoden', '4': 'Zielgruppenspezifische ErklÃ¤rungen mit Validierung', '5': 'Adaptive ErklÃ¤rbarkeit mit Nutzer-Feedback-Integration' } },
        'D4.2': { name: 'Informationspflichten', question: 'Werden die Informationspflichten gegenÃ¼ber Betreibern und Nutzern erfÃ¼llt?', indicators: { '1': 'Keine Informationsbereitstellung', '2': 'Grundlegende Produktinformation', '3': 'VollstÃ¤ndige Information gemÃ¤ÃŸ Art. 13 Abs. 3', '4': 'Proaktive, zielgruppengerechte Information', '5': 'Interaktive Informationssysteme mit Feedback' } },
        'D4.3': { name: 'Kommunikation von Grenzen', question: 'Werden FÃ¤higkeiten, Grenzen und Risiken des KI-Systems transparent kommuniziert?', indicators: { '1': 'Keine Kommunikation', '2': 'Allgemeine Hinweise', '3': 'Dokumentierte FÃ¤higkeiten und Grenzen', '4': 'Kontextspezifische Kommunikation mit Szenarien', '5': 'Dynamische Kommunikation mit Echtzeit-Updates' } },
        'D4.4': { name: 'KI-Kennzeichnung', question: 'Werden KI-generierte Inhalte und KI-Interaktionen gekennzeichnet?', indicators: { '1': 'Keine Kennzeichnung', '2': 'Teilweise Kennzeichnung', '3': 'Systematische Kennzeichnung aller KI-Interaktionen', '4': 'Automatisierte Kennzeichnung mit Metadaten', '5': 'Umfassende Kennzeichnung mit Provenienz-Tracking' } },
        'D4.5': { name: 'Prozesstransparenz', question: 'Ist der Governance-Prozess selbst transparent dokumentiert?', indicators: { '1': 'Keine Prozesstransparenz', '2': 'Grundlegende Prozessbeschreibung', '3': 'Dokumentierte Governance-Prozesse mit Rollen', '4': 'Transparente Prozesse mit Audit-MÃ¶glichkeit', '5': 'VollstÃ¤ndige Prozesstransparenz mit Ã¶ffentlichem Reporting' } },
      },
    },
    D5: {
      name: 'Menschliche Aufsicht',
      description: 'Konzeption fÃ¼r wirksame menschliche Aufsicht (HITL/HOTL), qualifiziertes Aufsichtspersonal, Interventionsmechanismen und PrÃ¤vention von Automation Bias gemÃ¤ÃŸ Art. 14.',
      criteria: {
        'D5.1': { name: 'Design fÃ¼r menschliche Aufsicht', question: 'Ist das KI-System fÃ¼r effektive menschliche Aufsicht konzipiert?', indicators: { '1': 'Keine BerÃ¼cksichtigung menschlicher Aufsicht', '2': 'Grundlegende ÃœberwachungsmÃ¶glichkeit', '3': 'Systematisches Human-in/on-the-loop Design', '4': 'Kontextadaptive Aufsichtsmechanismen', '5': 'Optimierte Mensch-Maschine-Interaktion mit Feedback-Loops' } },
        'D5.2': { name: 'Qualifikation der Aufsichtspersonen', question: 'Sind die Aufsichtspersonen ausreichend qualifiziert?', indicators: { '1': 'Keine definierten Qualifikationen', '2': 'Grundlegende Einweisung', '3': 'Definierte Kompetenzprofile und Schulungsprogramme', '4': 'Zertifizierte Qualifikation mit regelmÃ¤ÃŸiger Auffrischung', '5': 'Kontinuierliche Kompetenzentwicklung mit Leistungsmonitoring' } },
        'D5.3': { name: 'Interventionsmechanismen', question: 'Existieren klare Mechanismen fÃ¼r Eingriff, Korrektur und Abschaltung?', indicators: { '1': 'Keine InterventionsmÃ¶glichkeit', '2': 'Grundlegende AbschaltmÃ¶glichkeit', '3': 'Definierte Eskalations- und Interventionsprozesse', '4': 'Automatisierte Interventionsmechanismen mit Schwellwerten', '5': 'Adaptive Interventionssysteme mit prÃ¤diktiver Eskalation' } },
        'D5.4': { name: 'PrÃ¤vention von Automation Bias', question: 'Werden MaÃŸnahmen gegen Automation Bias und Algorithm Aversion ergriffen?', indicators: { '1': 'Keine MaÃŸnahmen', '2': 'Awareness-Schulungen', '3': 'Systematische MaÃŸnahmen (z.B. Decision-Support statt Decision-Making)', '4': 'Gemessene EffektivitÃ¤t der Bias-PrÃ¤vention', '5': 'Evidenzbasierte, kontinuierlich optimierte PrÃ¤ventionsmaÃŸnahmen' } },
        'D5.5': { name: 'Dokumentation von Aufsichtsentscheidungen', question: 'Werden Aufsichtsentscheidungen dokumentiert und reviewt?', indicators: { '1': 'Keine Dokumentation', '2': 'Ad-hoc Dokumentation', '3': 'Systematische Dokumentation aller Aufsichtsentscheidungen', '4': 'Automatisierte Erfassung mit Analyse-Dashboard', '5': 'Lernende Dokumentation mit Pattern-Erkennung' } },
      },
    },
    D6: {
      name: 'Technische Robustheit',
      description: 'Definierte Genauigkeitsmetriken, Robustheit gegenÃ¼ber StÃ¶rungen und adversarialen Angriffen, Cybersicherheit sowie kontinuierliches Monitoring mit Drift-Erkennung gemÃ¤ÃŸ Art. 15.',
      criteria: {
        'D6.1': { name: 'Genauigkeitsmetriken', question: 'Sind Genauigkeitsmetriken und Leistungsschwellen definiert?', indicators: { '1': 'Keine definierten Metriken', '2': 'Grundlegende Genauigkeitsmessung', '3': 'Definierte Metriken mit Schwellwerten fÃ¼r alle relevanten Dimensionen', '4': 'Automatisiertes Performance-Monitoring mit Alerting', '5': 'Adaptive Schwellwerte mit automatischer Rekalibrierung' } },
        'D6.2': { name: 'Robustheit', question: 'Ist das System robust gegen StÃ¶rungen, Fehler und adversariale Angriffe?', indicators: { '1': 'Keine RobustheitsmaÃŸnahmen', '2': 'Grundlegende Fehlerbehandlung', '3': 'Systematische Robustheitstests und -maÃŸnahmen', '4': 'Automatisierte adversariale Tests mit Metriken', '5': 'Kontinuierliche Robustheitsoptimierung mit Red-Teaming' } },
        'D6.3': { name: 'Cybersicherheit', question: 'Sind CybersicherheitsmaÃŸnahmen zum Schutz vor Manipulation implementiert?', indicators: { '1': 'Keine KI-spezifischen SicherheitsmaÃŸnahmen', '2': 'Standard-IT-SicherheitsmaÃŸnahmen', '3': 'KI-spezifische SicherheitsmaÃŸnahmen implementiert', '4': 'Umfassendes Security-Framework mit Penetrationstests', '5': 'Zero-Trust-Architektur mit kontinuierlichem Threat-Monitoring' } },
        'D6.4': { name: 'Monitoring und Drift-Erkennung', question: 'Ist ein kontinuierliches Monitoring mit Drift-Erkennung implementiert?', indicators: { '1': 'Kein Monitoring', '2': 'Manuelles periodisches Monitoring', '3': 'Automatisiertes Monitoring mit Drift-Erkennung', '4': 'Echtzeit-Monitoring mit automatisierten Alerts', '5': 'PrÃ¤diktives Monitoring mit automatischer Modell-Aktualisierung' } },
        'D6.5': { name: 'Fallback-Mechanismen', question: 'Existieren Fallback-Mechanismen und Graceful Degradation?', indicators: { '1': 'Keine Fallback-Mechanismen', '2': 'Einfache Fehlermeldung bei Systemausfall', '3': 'Definierte Fallback-Prozesse mit Graceful Degradation', '4': 'Automatisierte Fallback-Systeme mit Monitoring', '5': 'Resiliente Architektur mit selbstheilenden Mechanismen' } },
      },
    },
  },
  recommendations: {
    D1: 'Etablieren Sie ein formalisiertes KI-Risikomanagementsystem mit definierten Prozessen fÃ¼r Risikoidentifikation, -bewertung und -behandlung Ã¼ber den gesamten KI-Lebenszyklus.',
    D2: 'Implementieren Sie systematische Data-Governance-Prozesse einschlieÃŸlich DatenqualitÃ¤tsstandards, Bias-Erkennungsverfahren und durchgÃ¤ngiger Datenherkunftsdokumentation.',
    D3: 'VervollstÃ¤ndigen Sie die technische Dokumentation, etablieren Sie automatisierte Logging-Systeme und implementieren Sie eine durchgÃ¤ngige Versionierungsstrategie.',
    D4: 'StÃ¤rken Sie die Transparenz durch ErklÃ¤rbarkeitsmaÃŸnahmen, klare Informationspflichten und eine systematische Kennzeichnung KI-generierter Inhalte.',
    D5: 'Verbessern Sie die menschliche Aufsicht durch qualifizierte Aufsichtspersonen, klare Interventionsmechanismen und MaÃŸnahmen zur PrÃ¤vention von Automation Bias.',
    D6: 'ErhÃ¶hen Sie die technische Robustheit durch definierte Leistungsschwellen, CybersicherheitsmaÃŸnahmen, kontinuierliches Monitoring und Fallback-Mechanismen.',
  },
  compliance: {
    compliant: 'Konform',
    partial: 'Teilweise konform',
    nonCompliant: 'Nicht konform',
  },
  executive: {
    label: 'Executive Summary',
    systemReaches: 'Ihr KI-System â€ž{system}" erreicht eine Gesamtreife von {score}/5.0 (Stufe: {label}).',
    defaultSystem: 'KI-System',
    priorityAction: 'PrioritÃ¤rer Handlungsbedarf',
    and: 'und',
    riskNote: 'Bewertet als: {category}',
  },
  scoring: {
    title: 'Scoring-Methodik',
    howCalculated: 'So wurde Ihr Score berechnet',
    dimFormula: 'Dimensionsscore = Durchschnitt der bewerteten Kriterien (N/A ausgeschlossen)',
    overallFormula: 'Gesamtscore = gewichteter Durchschnitt der 6 Dimensionen (Gleichgewichtung)',
    gapThreshold: 'Gap-Schwelle = 3.0 (â€žDefiniert" nach CMMI) â€” der EU AI Act setzt fÃ¼r High-Risk-Systeme definierte Prozesse voraus',
    transparency: 'Transparenz ist ein Kernprinzip des EU AI Act (Art. 13). Diese Methodik basiert auf dem CMMI-Reifegradmodell, adaptiert fÃ¼r die Anforderungen der Art. 9â€“15.',
  },
  articleCompliance: {
    title: 'KonformitÃ¤tsstatus nach EU AI Act Artikeln',
  },
  heatmap: {
    title: 'Compliance-Heatmap (Kriterien-Matrix)',
  },
  maturityLevels: {
    1: 'Initial',
    2: 'Gesteuert',
    3: 'Definiert',
    4: 'Gemessen',
    5: 'Optimierend',
  },
  roadmap: {
    title: 'Compliance-Roadmap',
    month: 'Monat',
    phase1: 'Phase 1 (Monat 1â€“3)',
    phase2: 'Phase 2 (Monat 3â€“6)',
    phase3: 'Phase 3 (Monat 6â€“12)',
    phase1Desc: 'Kritische Gaps adressieren',
    phase2Desc: 'Signifikante Gaps adressieren',
    phase3Desc: 'Moderate Gaps optimieren',
    noGaps: 'Keine Gaps â€” alle Dimensionen konform.',
  },
  effort: {
    label: 'GeschÃ¤tzter Aufwand',
    D1: { hours: '80â€“120h', weeks: '4â€“8 Wochen', size: 'L' },
    D2: { hours: '60â€“100h', weeks: '3â€“6 Wochen', size: 'Mâ€“L' },
    D3: { hours: '40â€“80h', weeks: '2â€“4 Wochen', size: 'M' },
    D4: { hours: '60â€“90h', weeks: '3â€“6 Wochen', size: 'M' },
    D5: { hours: '40â€“70h', weeks: '2â€“4 Wochen', size: 'Sâ€“M' },
    D6: { hours: '80â€“120h', weeks: '4â€“8 Wochen', size: 'L' },
  },
  criteriaRec: {
    title: 'Kriterienbezogene Empfehlungen',
    noCriteria: 'Keine Kriterien unter Schwellenwert.',
    D1_1: 'Erstellen Sie ein dokumentiertes KI-Risikomanagementsystem mit definierten Rollen, Prozessen und Review-Zyklen.',
    D1_2: 'FÃ¼hren Sie eine systematische Risikoidentifikation Ã¼ber alle Lebenszyklusphasen hinweg ein (Entwicklung, Deployment, Betrieb).',
    D1_3: 'Definieren Sie eine formale Risikobewertungsmethodik (Wahrscheinlichkeit Ã— Schwere) basierend auf ISO 31000.',
    D1_4: 'Legen Sie RisikobehandlungsmaÃŸnahmen und Restrisiko-Akzeptanzkriterien fest und dokumentieren Sie diese.',
    D1_5: 'Etablieren Sie regelmÃ¤ÃŸige, dokumentierte Testverfahren zur Validierung Ihrer Risikobewertungen.',
    D1_6: 'FÃ¼hren Sie regelmÃ¤ÃŸige Review-Zyklen (min. quartalsweise) fÃ¼r Ihr Risikomanagementsystem ein.',
    D2_1: 'Definieren Sie messbare DatenqualitÃ¤tskriterien (VollstÃ¤ndigkeit, AktualitÃ¤t, Konsistenz) fÃ¼r Ihre KI-DatensÃ¤tze.',
    D2_2: 'Implementieren Sie systematische Bias-Analysen mit definierten Fairness-Metriken fÃ¼r Ihre Trainingsdaten.',
    D2_3: 'Dokumentieren Sie die vollstÃ¤ndige Datenherkunft (Data Lineage) von der Quelle bis zur Modellnutzung.',
    D2_4: 'Integrieren Sie DSGVO-Anforderungen systematisch in Ihre Data-Governance-Prozesse (Privacy by Design).',
    D2_5: 'Etablieren Sie regelmÃ¤ÃŸige DatenqualitÃ¤tsreviews und definieren Sie Korrekturprozesse.',
    D3_1: 'Erstellen Sie eine vollstÃ¤ndige technische Dokumentation gemÃ¤ÃŸ Anhang IV EU AI Act.',
    D3_2: 'Implementieren Sie strukturiertes Logging aller relevanten Systemereignisse und Entscheidungen.',
    D3_3: 'FÃ¼hren Sie eine systematische Versionierung aller Modell-Artefakte, Daten und Konfigurationen ein.',
    D3_4: 'Erstellen Sie systematische KonformitÃ¤tsnachweise gemÃ¤ÃŸ den regulatorischen Anforderungen.',
    D3_5: 'Richten Sie ein strukturiertes Dokumentenmanagementsystem mit Zugriffsrechten ein.',
    D4_1: 'Implementieren Sie ErklÃ¤rbarkeitsmaÃŸnahmen (z.B. SHAP, LIME) fÃ¼r Ihre KI-Entscheidungen.',
    D4_2: 'ErfÃ¼llen Sie die Informationspflichten gemÃ¤ÃŸ Art. 13 Abs. 3 gegenÃ¼ber Betreibern und Nutzern.',
    D4_3: 'Dokumentieren Sie FÃ¤higkeiten, Grenzen und bekannte Risiken Ihres KI-Systems transparent.',
    D4_4: 'Kennzeichnen Sie systematisch alle KI-generierten Inhalte und KI-Interaktionen.',
    D4_5: 'Dokumentieren Sie Ihre Governance-Prozesse transparent mit definierten Rollen und Verantwortlichkeiten.',
    D5_1: 'Konzipieren Sie Ihr KI-System mit Human-in-the-Loop (HITL) oder Human-on-the-Loop (HOTL) Mechanismen.',
    D5_2: 'Definieren Sie Kompetenzprofile und etablieren Sie Schulungsprogramme fÃ¼r Aufsichtspersonen.',
    D5_3: 'Definieren Sie klare Eskalations- und Interventionsprozesse inkl. Abschaltmechanismen.',
    D5_4: 'Implementieren Sie MaÃŸnahmen gegen Automation Bias (z.B. Decision-Support statt Decision-Making).',
    D5_5: 'Dokumentieren Sie systematisch alle Aufsichtsentscheidungen und deren BegrÃ¼ndungen.',
    D6_1: 'Definieren Sie Genauigkeitsmetriken und Leistungsschwellen fÃ¼r alle relevanten Dimensionen Ihres Systems.',
    D6_2: 'FÃ¼hren Sie systematische Robustheitstests durch (Stresstests, Edge Cases, adversariale Szenarien).',
    D6_3: 'Implementieren Sie KI-spezifische CybersicherheitsmaÃŸnahmen Ã¼ber die Standard-IT-Sicherheit hinaus.',
    D6_4: 'Etablieren Sie automatisiertes Monitoring mit Drift-Erkennung fÃ¼r Ihr KI-System.',
    D6_5: 'Definieren Sie Fallback-Prozesse und Graceful-Degradation-Mechanismen fÃ¼r SystemausfÃ¤lle.',
  },
  successCriteria: {
    title: 'Erfolgskriterien',
    description: 'Nachweisbare Kriterien fÃ¼r die Zielstufe:',
  },
  mapping: {
    title: 'Dimension-Artikel-Mapping',
    subtitle: 'Zuordnung der Governance-Dimensionen zu EU AI Act Artikeln',
    dimension: 'Dimension',
    primary: 'PrimÃ¤rzuordnung',
    secondary: 'SekundÃ¤rbezug',
    none: 'Kein Bezug',
    art9: 'Risikomanagement',
    art10: 'Daten-Governance',
    art11: 'Dokumentation',
    art13: 'Transparenz',
    art14: 'Menschl. Aufsicht',
    art15: 'Robustheit',
  },
  timeline: {
    title: 'EU AI Act Compliance-Zeitplan',
    subtitle: 'Wichtige Fristen fÃ¼r die Umsetzung des EU AI Act',
    m1: 'Verbotene KI-Praktiken (Art. 5) treten in Kraft. UnzulÃ¤ssige Systeme mÃ¼ssen abgeschaltet werden.',
    m2: 'Governance-Pflichten (Art. 17) und Verhaltenskodizes gelten. Benannte Stellen werden akkreditiert.',
    m3: 'VollstÃ¤ndige High-Risk-Anforderungen (Art. 9â€“15) gelten. KonformitÃ¤tsbewertung verpflichtend.',
    m4: 'VollstÃ¤ndige Anwendung aller Bestimmungen. Alle KI-Systeme mÃ¼ssen konform sein.',
    yourDeadline: 'Ihre Frist',
    remaining: 'Verbleibende Zeit',
    remainingText: 'ca. {months} Monate ({days} Tage) bis zur relevanten Frist',
  },
  glossary: {
    title: 'Glossar',
    subtitle: 'Wichtige Begriffe aus EU AI Act und KI-Governance',
    searchPlaceholder: 'Begriff suchen...',
    noResults: 'Keine Treffer gefunden.',
    terms: 'Begriffe',
    cmmi: { term: 'CMMI', def: 'Capability Maturity Model Integration â€” ein Reifegradmodell zur Bewertung und Verbesserung von Prozessen. Stufen 1 (Initial) bis 5 (Optimierend).' },
    highRisk: { term: 'Hochrisiko-KI-System', def: 'KI-System gemÃ¤ÃŸ Anhang III EU AI Act, das in sensiblen Bereichen eingesetzt wird (z.B. Kreditscoring, Personalauswahl). Unterliegt den vollstÃ¤ndigen Anforderungen der Art. 9â€“15.' },
    limitedRisk: { term: 'KI mit begrenztem Risiko', def: 'KI-System gemÃ¤ÃŸ Art. 50, das Transparenzpflichten unterliegt (z.B. Chatbots, Emotionserkennung, Deepfakes).' },
    minimalRisk: { term: 'Minimales Risiko', def: 'KI-Systeme ohne spezifische Pflichten unter dem EU AI Act (z.B. Spamfilter, Empfehlungssysteme).' },
    conformityAssessment: { term: 'KonformitÃ¤tsbewertung', def: 'Verfahren zur ÃœberprÃ¼fung, ob ein Hochrisiko-KI-System die Anforderungen des EU AI Act erfÃ¼llt (Art. 43).' },
    notifiedBody: { term: 'Benannte Stelle', def: 'Organisation, die KonformitÃ¤tsbewertungen fÃ¼r bestimmte Hochrisiko-KI-Systeme durchfÃ¼hrt.' },
    postMarket: { term: 'Post-Market Monitoring', def: 'Ãœberwachung eines KI-Systems nach Inverkehrbringen zur Sicherstellung der fortlaufenden KonformitÃ¤t (Art. 72).' },
    hitl: { term: 'HITL (Human-in-the-Loop)', def: 'Mensch ist direkt in den Entscheidungsprozess eingebunden und muss jede KI-Entscheidung bestÃ¤tigen oder ablehnen.' },
    hotl: { term: 'HOTL (Human-on-the-Loop)', def: 'Mensch Ã¼berwacht das KI-System und kann bei Bedarf eingreifen, das System trifft aber Entscheidungen eigenstÃ¤ndig.' },
    automationBias: { term: 'Automation Bias', def: 'Tendenz von Menschen, automatisierten Systemen Ã¼bermÃ¤ÃŸig zu vertrauen und eigene UrteilsfÃ¤higkeit zu vernachlÃ¤ssigen.' },
    dataGovernance: { term: 'Data Governance', def: 'Systematische Verwaltung von DatenqualitÃ¤t, -verfÃ¼gbarkeit, -integritÃ¤t und -sicherheit.' },
    biasDetection: { term: 'Bias-Erkennung', def: 'Systematische Verfahren zur Identifikation von Verzerrungen in Trainingsdaten oder Modellergebnissen.' },
    dataLineage: { term: 'Data Lineage', def: 'Nachverfolgung der Herkunft, Verarbeitung und Nutzung von Daten von der Quelle bis zum Endprodukt.' },
    explainability: { term: 'ErklÃ¤rbarkeit', def: 'FÃ¤higkeit, KI-Entscheidungen fÃ¼r Menschen nachvollziehbar zu machen. Methoden: SHAP, LIME, Attention Maps.' },
    gracefulDegradation: { term: 'Graceful Degradation', def: 'FÃ¤higkeit eines Systems, bei TeilausfÃ¤llen weiterhin eingeschrÃ¤nkt funktionsfÃ¤hig zu bleiben.' },
    driftDetection: { term: 'Drift-Erkennung', def: 'Monitoring-Verfahren zur Erkennung von VerÃ¤nderungen in Datenverteilungen oder Modellverhalten Ã¼ber die Zeit.' },
    adversarial: { term: 'Adversariale Angriffe', def: 'Gezielte Manipulation von KI-Systemen durch speziell prÃ¤parierte Eingabedaten.' },
    riskAppetite: { term: 'Risikoappetit', def: 'Das Niveau an Risiko, das eine Organisation bereit ist zu akzeptieren.' },
    maturityModel: { term: 'Reifegradmodell', def: 'Framework zur Bewertung des Entwicklungsstands von Prozessen auf einer definierten Skala.' },
    dimScore: { term: 'Dimensionsscore', def: 'Durchschnittlicher Score aller bewerteten Kriterien einer Governance-Dimension (N/A ausgeschlossen).' },
  },
  maturityDist: {
    title: 'Maturity-Stufenverteilung',
    subtitle: 'Verteilung der Kriterien auf Reifegrad-Stufen',
    level1: 'Initial',
    level2: 'Gesteuert',
    level3: 'Definiert',
    level4: 'Gemessen',
    level5: 'Optimierend',
    total: '{n} Kriterien bewertet',
  },
  consistency: {
    warning: 'Konsistenzhinweis: Ihre Bewertungen in {dim} variieren stark ({min}â€“{max}). MÃ¶chten Sie diese nochmal prÃ¼fen?',
  },
  raci: {
    title: 'Verantwortlichkeiten-Matrix (RACI)',
    subtitle: 'Zuweisung von Rollen und Verantwortlichkeiten pro Governance-Dimension',
    dimension: 'Dimension',
    responsible: 'Verantwortlich',
    accountable: 'Rechenschaftspflichtig',
    consulted: 'Konsultiert',
    informed: 'Informiert',
  },
  scoping: {
    governanceOfficerLabel: 'Dedizierter AI-Governance-Beauftragter',
    governanceOfficerYes: 'Ja',
    governanceOfficerNo: 'Nein',
    existingFrameworksLabel: 'Bestehende Compliance-Frameworks',
    existingFrameworksPlaceholder: 'z.B. ISO 27001, SOC2, DSGVO',
    numAiSystemsLabel: 'Anzahl KI-Systeme in Produktion',
    numAiSystems1: '1',
    numAiSystems2_5: '2â€“5',
    numAiSystems6_20: '6â€“20',
    numAiSystems20plus: '20+',
  },
  practiceExamples: {
    title: 'Praxisbeispiel',
    level2: 'Stufe 2',
    level3: 'Stufe 3',
  },
  pdf: {
    reportTitle: 'AI Governance Assessment Report',
    executiveSummary: 'Executive Summary',
    dimensionResults: 'Dimensionsergebnisse',
    gapAnalysis: 'Gap-Analyse & Empfehlungen',
    methodology: 'Methodik',
    compliant: 'Konform',
    partial: 'Teilweise',
    nonCompliant: 'Nicht konform',
    rated: 'bewertet',
    severity: 'Schwere',
    recommendation: 'Empfehlung',
    dimension: 'Dimension',
    score: 'Score',
    status: 'Status',
    details: 'Details',
    summaryText: 'Das KI-System <strong>{name}</strong> erreicht eine Gesamtreife von <strong style="color:#5C6BC0;">{score}/5.0</strong> (Stufe: <strong>{label}</strong>). Von 6 Governance-Dimensionen sind <strong style="color:#22c55e;">{compliant} konform</strong>, <strong style="color:#eab308;">{partial} teilweise konform</strong> und <strong style="color:#ef4444;">{nonCompliant} nicht konform</strong>.',
    methodologyText: 'Dieses Assessment basiert auf dem CMMI-basierten Reifegradmodell fuer KI-Governance gemaess EU AI Act (VO 2024/1689), Art. 9â€“15. 31 Kriterien in 6 Dimensionen werden auf einer Skala von 1 (Initial) bis 5 (Optimierend) bewertet. Dimensionsscore = Durchschnitt der bewerteten Kriterien (N/A ausgeschlossen). Gesamtscore = gewichteter Durchschnitt der 6 Dimensionen. Gap-Schwelle fuer Hochrisiko-Systeme: 3.0 (Definiert).',
    generatedAt: 'Generiert am {date} | KI-Governance-Bewertungsframework | EU AI Act Compliance',
  },
  cmmiLevels: {
    1: 'Stufe 1 â€” Initial: Es gibt keinen formalen Prozess. Entscheidungen werden ad-hoc und reaktiv getroffen. Kein dokumentiertes Vorgehen.',
    2: 'Stufe 2 â€” Gesteuert: Grundlegende Prozesse existieren, sind aber nicht standardisiert. Ergebnisse hÃ¤ngen von Einzelpersonen ab.',
    3: 'Stufe 3 â€” Definiert: Dokumentierte, wiederholbare Prozesse existieren und werden organisationsweit eingehalten. Dies ist die Mindestanforderung fÃ¼r EU AI Act KonformitÃ¤t.',
    4: 'Stufe 4 â€” Gemessen: Prozesse werden quantitativ Ã¼berwacht und gesteuert. KPIs und Metriken sind definiert und werden aktiv genutzt.',
    5: 'Stufe 5 â€” Optimierend: Kontinuierliche Verbesserung durch datengetriebene Optimierung. Best-Practice-Sharing und prÃ¤ventive MaÃŸnahmen.',
  },
} as const
